{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#from sensitivity_plot import sensitivity_plot\n",
    "#import statsmodels.api as sm\n",
    "import numbers\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import linear_model\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import pylab \n",
    "import scipy.stats as stats\n",
    "from whitebox.eval import WhiteBoxSensitivity\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble.partial_dependence import partial_dependence, plot_partial_dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./datasets/final_data.csv', low_memory=False)\n",
    "#final_data = final_data.drop('LanguageRecommendationSelect', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5617, 282)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for details on data cleaning see'Data_Cleaning.ipynb'\n",
    "#raw data has 5617 rows\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5617, 282)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get rid of all NAs\n",
    "#final_data = final_data.dropna()\n",
    "df = df.reset_index(drop=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependentVar = 'JobSatisfaction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_cols = [col for col in df.columns if 'WorkToolsSelect' in col]\n",
    "df = df.drop(spike_cols, axis=1)\n",
    "spike_cols = [col for col in df.columns if 'WorkHardwareSelect' in col]\n",
    "df = df.drop(spike_cols, axis=1)\n",
    "\n",
    "#drop country specific axis as it's hard to interpret and clouds the impact of other variables\n",
    "df= df.drop('Average Salary Within Country', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4364, 221)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop people who don't consider themselves Data Scientists\n",
    "\n",
    "df = df[df['DataScienceIdentitySelect'] !='No']\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4364.000000\n",
       "mean        6.880614\n",
       "std         2.108277\n",
       "min         1.000000\n",
       "25%         6.000000\n",
       "50%         7.000000\n",
       "75%         8.000000\n",
       "max        10.000000\n",
       "Name: JobSatisfaction, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[dependentVar].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1    4.0\n",
       "0.2    5.0\n",
       "0.3    6.0\n",
       "0.4    7.0\n",
       "0.5    7.0\n",
       "0.6    8.0\n",
       "0.7    8.0\n",
       "0.8    9.0\n",
       "0.9    9.0\n",
       "Name: JobSatisfaction, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop columns with WorkToolsSelect_C as they are sparse and not important here and have a ++ that is problematic\n",
    "df['JobSatisfaction'].quantile([.1,.2,.3,.4,.5,.6,.7,.8,.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#convert string variables to categorical variables \n",
    "df[df.select_dtypes(['object']).columns] = df.select_dtypes(['object']).apply(lambda x: x.astype('category'))\n",
    "\n",
    "# select only those columns which are categorical in nature and make a copy for modeling\n",
    "df.select_dtypes(include = ['category'])\n",
    "model_df = df.copy(deep = True)\n",
    "\n",
    "# create dummies example using all categorical columns\n",
    "# this naming convention must be precise for WhiteBox to recognize what dummies are associated with what variables\n",
    "dummies = pd.concat([pd.get_dummies(model_df.loc[:, col],dummy_na = True,  prefix = col) for col in model_df.select_dtypes(include = ['category']).columns], axis = 1)\n",
    "\n",
    "# add the dummies to the numeric dataframe for modeling\n",
    "finaldf = pd.concat([model_df.select_dtypes(include = [np.number]), dummies], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make train and test samles\n",
    "X_train, X_test, y_train, y_test = train_test_split(finaldf.loc[:, finaldf.columns != dependentVar], df.loc[:, dependentVar], test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.01, n_estimators=50, n_jobs=1,\n",
       "           oob_score=True, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make a Random Forest object trained to predict Job Satisfaction \n",
    "Rf = RandomForestRegressor(n_estimators=50, min_weight_fraction_leaf = .01,  oob_score=True)\n",
    "#Rf.fit(xTrain,final_data['JobSatisfaction'])\n",
    "Rf.fit(finaldf.loc[:, finaldf.columns != dependentVar],df.loc[:, dependentVar])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.19060532 0.17083364 0.15918933 0.16102931 0.13583847]\n",
      "0.16349921475141713\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(Rf, finaldf.loc[:, finaldf.columns != dependentVar], df.loc[:, dependentVar], cv=5)\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.05, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.01,\n",
       "             n_estimators=200, presort='auto', random_state=25,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est = GradientBoostingRegressor(n_estimators=200, learning_rate=.05,  min_weight_fraction_leaf = .01, loss='ls', random_state = 25)\n",
    "est.fit(finaldf.loc[:, finaldf.columns != dependentVar], finaldf.loc[:, dependentVar])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.19032543 0.1946704  0.21180414 0.21380157 0.17218884]\n",
      "0.19655807563077346\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(est, finaldf.loc[:, finaldf.columns != dependentVar], df.loc[:, dependentVar], cv=5)\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.03, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit lasso model\n",
    "lass = linear_model.Lasso(alpha=0.03)\n",
    "lass.fit(finaldf.loc[:, finaldf.columns != dependentVar],df.loc[:, dependentVar])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17965282 0.20106627 0.20329975 0.20170372 0.16273457]\n",
      "0.18969142479756015\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(lass, finaldf.loc[:, finaldf.columns != dependentVar], df.loc[:, dependentVar], cv=5)\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate coefficients and then print them\n",
    "coef_dict = {}\n",
    "for coef, feat in zip(lass.coef_,X_train.columns):\n",
    "    if coef != 0:\n",
    "        coef_dict[feat] = round(coef,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Varialbe</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>WorkChallengeFrequencyPolitics_Most of the time</td>\n",
       "      <td>-0.623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Continent_Asia</td>\n",
       "      <td>-0.453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>TitleFit_Poorly</td>\n",
       "      <td>-0.395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>SalaryChange_Has stayed about the same (has no...</td>\n",
       "      <td>-0.285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>RemoteWork_Never</td>\n",
       "      <td>-0.214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>WorkChallengeFrequencyTalent_Most of the time</td>\n",
       "      <td>-0.171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>CurrentEmployerType_Employed by a company that...</td>\n",
       "      <td>-0.143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>WorkChallengeFrequencyDataAccess_Never</td>\n",
       "      <td>-0.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>WorkChallengeFrequencyDirtyData_Never</td>\n",
       "      <td>-0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>JobFunctionSelect_Analyze and understand data ...</td>\n",
       "      <td>-0.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>DataScienceIdentitySelect_Sort of (Explain more)</td>\n",
       "      <td>-0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>WorkMethodsFrequencyTextAnalysis_Never</td>\n",
       "      <td>-0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NumberChallenges</td>\n",
       "      <td>-0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LearningPlatformUsefulnessDocumentation_nan</td>\n",
       "      <td>-0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>WorkChallengeFrequencyPrivacy_Never</td>\n",
       "      <td>-0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LearningPlatformUsefulnessConferences_nan</td>\n",
       "      <td>-0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>WorkDataVisualizations_Less than 10% of projects</td>\n",
       "      <td>-0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>WorkDataVisualizations_10-25% of projects</td>\n",
       "      <td>-0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LearningCategoryOnlineCourses</td>\n",
       "      <td>-0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LearningCategoryKaggle</td>\n",
       "      <td>-0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>WorkToolsFrequencyJupyter_Never</td>\n",
       "      <td>-0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LearningCategorySelftTaught</td>\n",
       "      <td>-0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LearningCategoryUniversity</td>\n",
       "      <td>-0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Unnamed: 0</td>\n",
       "      <td>-0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>CurrentEmployerType_Employed by a company that...</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TimeVisualizing</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LearningCategoryWork</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TimeOtherSelect</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CurrentJobTitleSelect_Data Scientist</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TimeGatheringData</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TimeFindingInsights</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TimeProduction</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TimeModelBuilding</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NumberPlatforms</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>WorkToolsFrequencyJupyter_Most of the time</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>EmployerSizeChange_Increased slightly</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>CurrentEmployerType_Employed by a company that...</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Continent_Other</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Hardware Types Used</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Number of Algorithims</td>\n",
       "      <td>0.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Percent Above/Below Average Salary</td>\n",
       "      <td>0.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LearningPlatformUsefulnessYouTube_nan</td>\n",
       "      <td>0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>UniversityImportance_Very important</td>\n",
       "      <td>0.068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>WorkMethodsFrequencyDataVisualization_Most of ...</td>\n",
       "      <td>0.073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>WorkChallengeFrequencyTalent_Never</td>\n",
       "      <td>0.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>WorkChallengeFrequencyUnusedResults_Never</td>\n",
       "      <td>0.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>EmployerSizeChange_Increased significantly</td>\n",
       "      <td>0.192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>SalaryChange_Has increased 20% or more</td>\n",
       "      <td>0.299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TitleFit_Perfectly</td>\n",
       "      <td>0.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>WorkChallengeFrequencyPolitics_Never</td>\n",
       "      <td>0.586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Varialbe  Coefficient\n",
       "33    WorkChallengeFrequencyPolitics_Most of the time       -0.623\n",
       "46                                     Continent_Asia       -0.453\n",
       "20                                    TitleFit_Poorly       -0.395\n",
       "45  SalaryChange_Has stayed about the same (has no...       -0.285\n",
       "43                                   RemoteWork_Never       -0.214\n",
       "37      WorkChallengeFrequencyTalent_Most of the time       -0.171\n",
       "49  CurrentEmployerType_Employed by a company that...       -0.143\n",
       "40             WorkChallengeFrequencyDataAccess_Never       -0.079\n",
       "36              WorkChallengeFrequencyDirtyData_Never       -0.070\n",
       "28  JobFunctionSelect_Analyze and understand data ...       -0.064\n",
       "24   DataScienceIdentitySelect_Sort of (Explain more)       -0.059\n",
       "32             WorkMethodsFrequencyTextAnalysis_Never       -0.042\n",
       "14                                   NumberChallenges       -0.040\n",
       "22        LearningPlatformUsefulnessDocumentation_nan       -0.036\n",
       "39                WorkChallengeFrequencyPrivacy_Never       -0.036\n",
       "21          LearningPlatformUsefulnessConferences_nan       -0.035\n",
       "42   WorkDataVisualizations_Less than 10% of projects       -0.018\n",
       "41          WorkDataVisualizations_10-25% of projects       -0.017\n",
       "2                       LearningCategoryOnlineCourses       -0.010\n",
       "5                              LearningCategoryKaggle       -0.010\n",
       "30                    WorkToolsFrequencyJupyter_Never       -0.008\n",
       "1                         LearningCategorySelftTaught       -0.007\n",
       "4                          LearningCategoryUniversity       -0.004\n",
       "12                                         Unnamed: 0       -0.001\n",
       "50  CurrentEmployerType_Employed by a company that...        0.000\n",
       "9                                     TimeVisualizing        0.001\n",
       "3                                LearningCategoryWork        0.002\n",
       "11                                    TimeOtherSelect        0.003\n",
       "18               CurrentJobTitleSelect_Data Scientist        0.003\n",
       "6                                   TimeGatheringData        0.003\n",
       "10                                TimeFindingInsights        0.007\n",
       "8                                      TimeProduction        0.008\n",
       "7                                   TimeModelBuilding        0.009\n",
       "0                                                 Age        0.016\n",
       "15                                    NumberPlatforms        0.018\n",
       "29         WorkToolsFrequencyJupyter_Most of the time        0.023\n",
       "26              EmployerSizeChange_Increased slightly        0.025\n",
       "48  CurrentEmployerType_Employed by a company that...        0.025\n",
       "47                                    Continent_Other        0.027\n",
       "16                                Hardware Types Used        0.029\n",
       "17                              Number of Algorithims        0.047\n",
       "13                 Percent Above/Below Average Salary        0.049\n",
       "23              LearningPlatformUsefulnessYouTube_nan        0.057\n",
       "27                UniversityImportance_Very important        0.068\n",
       "31  WorkMethodsFrequencyDataVisualization_Most of ...        0.073\n",
       "38                 WorkChallengeFrequencyTalent_Never        0.076\n",
       "35          WorkChallengeFrequencyUnusedResults_Never        0.077\n",
       "25         EmployerSizeChange_Increased significantly        0.192\n",
       "44             SalaryChange_Has increased 20% or more        0.299\n",
       "19                                 TitleFit_Perfectly        0.325\n",
       "34               WorkChallengeFrequencyPolitics_Never        0.586"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(coef_dict.items()), columns=['Varialbe', 'Coefficient']).sort_values(['Coefficient'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test validity of assumptions of the regression's coefficients \n",
    "y = y_test\n",
    "predicted = lass.predict(X_test)\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(y, predicted, edgecolors=(0, 0, 0))\n",
    "#ax.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=6)\n",
    "ax.set_xlabel('Measured')\n",
    "ax.set_ylabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y_test\n",
    "predicted = lass.predict(X_test)\n",
    "error2 = (predicted-y_test)\n",
    "stats.probplot(error2, dist=\"norm\", plot=pylab)\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age\n",
      "LearningCategorySelftTaught\n",
      "LearningCategoryOnlineCourses\n",
      "LearningCategoryWork\n",
      "LearningCategoryUniversity\n",
      "LearningCategoryKaggle\n",
      "TimeGatheringData\n",
      "TimeModelBuilding\n",
      "TimeProduction\n",
      "TimeVisualizing\n",
      "TimeFindingInsights\n",
      "TimeOtherSelect\n",
      "Unnamed: 0\n",
      "Percent Above/Below Average Salary\n",
      "NumberChallenges\n",
      "NumberPlatforms\n",
      "Hardware Types Used\n",
      "Number of Algorithims\n",
      "CurrentJobTitleSelect_Data Scientist\n",
      "TitleFit_Perfectly\n",
      "TitleFit_Poorly\n",
      "LearningPlatformUsefulnessConferences_nan\n",
      "LearningPlatformUsefulnessDocumentation_nan\n",
      "LearningPlatformUsefulnessYouTube_nan\n",
      "DataScienceIdentitySelect_Sort of (Explain more)\n",
      "EmployerSizeChange_Increased significantly\n",
      "EmployerSizeChange_Increased slightly\n",
      "UniversityImportance_Very important\n",
      "JobFunctionSelect_Analyze and understand data to influence product or business decisions\n",
      "WorkToolsFrequencyJupyter_Most of the time\n",
      "WorkToolsFrequencyJupyter_Never\n",
      "WorkMethodsFrequencyDataVisualization_Most of the time\n",
      "WorkMethodsFrequencyTextAnalysis_Never\n",
      "WorkChallengeFrequencyPolitics_Most of the time\n",
      "WorkChallengeFrequencyPolitics_Never\n",
      "WorkChallengeFrequencyUnusedResults_Never\n",
      "WorkChallengeFrequencyDirtyData_Never\n",
      "WorkChallengeFrequencyTalent_Most of the time\n",
      "WorkChallengeFrequencyTalent_Never\n",
      "WorkChallengeFrequencyPrivacy_Never\n",
      "WorkChallengeFrequencyDataAccess_Never\n",
      "WorkDataVisualizations_10-25% of projects\n",
      "WorkDataVisualizations_Less than 10% of projects\n",
      "RemoteWork_Never\n",
      "SalaryChange_Has increased 20% or more\n",
      "SalaryChange_Has stayed about the same (has not increased or decreased more than 5%)\n",
      "Continent_Asia\n",
      "Continent_Other\n",
      "CurrentEmployerType_Employed by a company that doesn't perform advanced analytics_No\n",
      "CurrentEmployerType_Employed by a company that performs advanced analytics_No\n",
      "CurrentEmployerType_Employed by a company that performs advanced analytics_Yes\n"
     ]
    }
   ],
   "source": [
    "j=221\n",
    "\n",
    "\n",
    "for i in range(0,len(coef_dict)):\n",
    "    fig, ax = plt.subplots()\n",
    "    temp = X_test[list(coef_dict)[i]]\n",
    "    x = temp.sort_values()\n",
    "    #print(len(temp.sort_values))\n",
    "    y=error2\n",
    "    fit = np.polyfit(x, y, deg=1)\n",
    "    ax.plot(x, fit[0] * x + fit[1], color='red')\n",
    "    ax.scatter(x, y)\n",
    "    print(list(coef_dict)[i])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = est.feature_importances_\n",
    "feature_length = feature_importance.shape[0]\n",
    "feature_10 = feature_length-20\n",
    "# make importances relative to max importance\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot top 10 features based on importance\n",
    "feature_importance = est.feature_importances_\n",
    "feature_length = feature_importance.shape[0]\n",
    "feature_10 = feature_length-20\n",
    "# make importances relative to max importance\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "#sorted_idx=sorted_idx[0:10]\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.barh(pos[feature_10:feature_length], feature_importance[sorted_idx][feature_10:feature_length], align='center')\n",
    "plt.yticks(pos[feature_10:feature_length], np.array(list(X_train))[sorted_idx][feature_10:feature_length])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WorkChallengeFrequencyPolitics</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Most of the time</th>\n",
       "      <td>462.0</td>\n",
       "      <td>5.402597</td>\n",
       "      <td>2.447327</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Never</th>\n",
       "      <td>2628.0</td>\n",
       "      <td>7.298706</td>\n",
       "      <td>1.938384</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Often</th>\n",
       "      <td>691.0</td>\n",
       "      <td>6.415340</td>\n",
       "      <td>2.040814</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rarely</th>\n",
       "      <td>59.0</td>\n",
       "      <td>6.830508</td>\n",
       "      <td>2.190517</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sometimes</th>\n",
       "      <td>524.0</td>\n",
       "      <td>6.706107</td>\n",
       "      <td>1.943140</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 count      mean       std  min  25%  50%  \\\n",
       "WorkChallengeFrequencyPolitics                                              \n",
       "Most of the time                 462.0  5.402597  2.447327  1.0  4.0  6.0   \n",
       "Never                           2628.0  7.298706  1.938384  1.0  6.0  8.0   \n",
       "Often                            691.0  6.415340  2.040814  1.0  5.0  7.0   \n",
       "Rarely                            59.0  6.830508  2.190517  1.0  5.0  7.0   \n",
       "Sometimes                        524.0  6.706107  1.943140  1.0  6.0  7.0   \n",
       "\n",
       "                                75%   max  \n",
       "WorkChallengeFrequencyPolitics             \n",
       "Most of the time                7.0  10.0  \n",
       "Never                           9.0  10.0  \n",
       "Often                           8.0  10.0  \n",
       "Rarely                          8.0  10.0  \n",
       "Sometimes                       8.0  10.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['WorkChallengeFrequencyPolitics'])['JobSatisfaction'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WorkChallengeFrequencyPolitics\n",
       "Most of the time    0.105866\n",
       "Never               0.602200\n",
       "Often               0.158341\n",
       "Rarely              0.013520\n",
       "Sometimes           0.120073\n",
       "Name: WorkChallengeFrequencyPolitics, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['WorkChallengeFrequencyPolitics'])['WorkChallengeFrequencyPolitics'].count()/df['WorkChallengeFrequencyPolitics'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Entire_Population'] = 'Entire Population'\n",
    "df['Entire_Population'] = pd.Categorical(df['Entire_Population'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Entire_Population']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spike_cols = [col for col in df.columns if 'Population' in col]\n",
    "spike_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'Average Salary Within Country' : 'Average Salary Within Country',  \n",
    "keepfeaturelist = [ 'WorkChallengeFrequencyPolitics' , \n",
    "               'WorkDataVisualizations' ,\n",
    "               'MLToolNextYearSelect' ,\n",
    "                             'TimeModelBuilding' ,\n",
    "                             'Number of Algorithims',\n",
    "                             'SalaryChange' ,\n",
    "                             'EmployerSizeChange' ,\n",
    "                             'Percent Above/Below Average Salary' ,              \n",
    "                             'LearningCategoryWork',\n",
    "                             'LearningCategoryOnlineCourses',\n",
    "                             'LearningPlatformUsefulnessCompany' ,\n",
    "                             'WorkChallengeFrequencyDomainExpertise' ,\n",
    "                             'WorkChallengeFrequencyTalent' ,\n",
    "               'WorkChallengeFrequencyML' ,\n",
    "                             'RemoteWork',\n",
    "                             'Age' ,\n",
    "                             'TitleFit' ,\n",
    "                                     'DataScienceIdentitySelect' ,\n",
    "             \n",
    "                             'Continent' ,\n",
    "                             'SalaryChange' ,\n",
    "                             'JobSatisfaction' ,\n",
    "                             'AlgorithmUnderstandingLevel' ,\n",
    "                              'UniversityImportance',\n",
    "                   'Entire_Population'\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "WB=None\n",
    "\n",
    "#'Continent','DataScienceIdentitySelect','WorkChallengeFrequencyPolitics', 'AlgorithmUnderstandingLevel',\n",
    "WB = WhiteBoxSensitivity(est,\n",
    "                   model_df=finaldf,\n",
    "                   ydepend=dependentVar,\n",
    "                   cat_df=df,\n",
    "                   keepfeaturelist=keepfeaturelist,\n",
    "                   groupbyvars=[ 'Entire_Population'],\n",
    "                   verbose=None,\n",
    "                    std_num=1,\n",
    "                    autoformat_types=True,\n",
    "                   )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Complete: 95%Wall time: 17.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "WB.run(output_type='html',\n",
    "       output_path='SENSITIVITYTEST.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = finaldf.loc[:, finaldf.columns != dependentVar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.534278509091686"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.predict(temp[df['WorkChallengeFrequencyPolitics']=='Most of the time']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.600403897545416"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "#base prediction on a subset of the data \n",
    "np.nanmedian(est.predict(temp[temp['WorkChallengeFrequencyPolitics_Most of the time'] == 1 ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "polcopy = temp.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Never, Most of the time, Often, Rarely, Sometimes]\n",
       "Categories (5, object): [Never, Most of the time, Often, Rarely, Sometimes]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['WorkChallengeFrequencyPolitics'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manually setting most of the time to 0 and never to 1 \n",
    "polcopy.loc[temp['WorkChallengeFrequencyPolitics_Most of the time'] == 1  ,'WorkChallengeFrequencyPolitics_Most of the time'] = 0\n",
    "polcopy.loc[temp['WorkChallengeFrequencyPolitics_Most of the time'] == 1 , 'WorkChallengeFrequencyPolitics_Never'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.815419347545813"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanmedian(est.predict(polcopy.loc[temp['WorkChallengeFrequencyPolitics_Most of the time'] == 1 ]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WorkChallengeFrequencyPolitics_Most of the time    0.0\n",
       "WorkChallengeFrequencyPolitics_Never               1.0\n",
       "WorkChallengeFrequencyPolitics_Often               0.0\n",
       "WorkChallengeFrequencyPolitics_Rarely              0.0\n",
       "WorkChallengeFrequencyPolitics_Sometimes           0.0\n",
       "WorkChallengeFrequencyPolitics_nan                 0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polcopy.loc[temp['WorkChallengeFrequencyPolitics_Most of the time'] == 1 ].filter(regex='WorkChallengeFrequencyPolitics').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_col='WorkChallengeFrequencyPolitics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df = df\n",
    "copydf = finaldf.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_type_cols = ['{}_{}'.format(cur_col, cat) for cat in cat_df.loc[:, cur_col].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WorkChallengeFrequencyPolitics_Never']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modal_val = str(cat_df[cur_col].mode().values[0])\n",
    "mode_col = list(filter(lambda x: modal_val in x, all_type_cols))\n",
    "mode_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "copydf.loc[:, mode_col] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dbyler\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:523: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n",
      "C:\\Users\\dbyler\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py:3239: UserWarning: Attempting to set identical bottom==top results\n",
      "in singular transformations; automatically expanding.\n",
      "bottom=4.896257010944538e-16, top=4.896257010944538e-16\n",
      "  'bottom=%s, top=%s') % (bottom, top))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#\n",
    "for i in range(0,finaldf.loc[:, finaldf.columns != dependentVar].shape[1]):\n",
    "                  my_plots = plot_partial_dependence(est, features=[i], # column numbers of plots we want to show \n",
    "                        X=finaldf.loc[:, finaldf.columns != dependentVar],            # raw predictors data.\n",
    "                              #feature_names=[finaldf.columns[finaldf.columns != dependentVar][i]],\n",
    "                                   grid_resolution=100) # number of values to plot on x axis\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4364, 1066)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Item wrong length 1066 instead of 4364.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-106-3667fa56050c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'all'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfinaldf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfinaldf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mdependentVar\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1956\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1957\u001b[0m             \u001b[1;31m# either boolean or fancy integer index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1958\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1959\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1960\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1993\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1994\u001b[0m                 raise ValueError('Item wrong length %d instead of %d.' %\n\u001b[1;32m-> 1995\u001b[1;33m                                  (len(key), len(self.index)))\n\u001b[0m\u001b[0;32m   1996\u001b[0m             \u001b[1;31m# check_bool_indexer will throw exception if Series key cannot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1997\u001b[0m             \u001b[1;31m# be reindexed to match DataFrame rows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Item wrong length 1066 instead of 4364."
     ]
    }
   ],
   "source": [
    "plt.close('all')\n",
    "finaldf[finaldf.columns != dependentVar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#seeing if we get a differnet result for a classifier\n",
    "\n",
    "y_train_binary = np.where(y_train < y_train.mean() , 1, 0)\n",
    "y_test_binary = np.where(y_test < y_train.mean() , 1, 0)\n",
    "\n",
    "modelObject = GradientBoostingClassifier(n_estimators=500,   max_features = 'sqrt', learning_rate=.01)\n",
    "modelObject.fit(X_train,y_train_binary)\n",
    "y_in_pred = modelObject.predict(X_train)\n",
    "y_out_pred=modelObject.predict(X_test)\n",
    "print(accuracy_score(y_train_binary, y_in_pred)) \n",
    "print(accuracy_score(y_test_binary, y_out_pred))  \n",
    "\n",
    "# Plot top 10 feature importance\n",
    "feature_importance = modelObject.feature_importances_\n",
    "feature_length = feature_importance.shape[0]\n",
    "feature_10 = feature_length-15\n",
    "# make importances relative to max importance\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "#sorted_idx=sorted_idx[0:10]\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.barh(pos[feature_10:feature_length], feature_importance[sorted_idx][feature_10:feature_length], align='center')\n",
    "plt.yticks(pos[feature_10:feature_length], np.array(list(X_train))[sorted_idx][feature_10:feature_length])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#feature dictionary for when the dependent variable is binary\n",
    "\n",
    "FeatureDict = {'WorkChallengeFrequencyPolitics' : 'Frequency of Political Work Issues', \n",
    "               'WorkChallengeUnusedResults' : 'Frequency of Results Not Being Used', \n",
    "               'Number of Algorithims' : 'Number of Algorithims',\n",
    "               'TitleFit' : 'Goodness of Title Fit',\n",
    "               'Number of Code Sharing Methods': 'Number of Code Sharing Methods',\n",
    "               'LearningCategoryOnlineCourses' : 'Share of Learning Done Online', \n",
    "               'Continent' : 'Continent',\n",
    "               'SalaryChange' : 'Salary Change',\n",
    "               'LearningCategoryWork' : 'Proportion of Knowledge Gained From Work',\n",
    "               'EmployerSizeChange' : 'Change in Employer Size',\n",
    "               'WorkChallengeFrequencyTalent' : 'Difficulty Sourcing Talented Colleagues',\n",
    "               'WorkProductionFrequency' : 'Frequency of Production-style Work',\n",
    "               'TimeModelBuilding' : 'Proportion of Time Spent Model Building',\n",
    "               'CompnesationUSD' : 'Compensation ($)',\n",
    "               'RemoteWork' : 'Frequency of Remote Work',\n",
    "               'DataScienceIdentitySelect' : 'Views self as Data Scientist',\n",
    "               'WorkChallengeFrequencyML' : 'Frequency of working with machine learning',\n",
    "               'UniversityImportance' : 'Importance of a University degree'\n",
    "              }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calls to our new functions for the classifiers go here\n",
    "\n",
    "#Error plot\n",
    "\n",
    "#Sensitivty plot\n",
    "print(sensitivity_plot(X_test.join(y_test),'JobSatisfaction',cont_independentVar,cat_independentVar,\n",
    "                               Rf,ouputPath,'Data Scienctist Job Satisfaction',['Continent', 'WorkChallengeFrequencyPolitics']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
