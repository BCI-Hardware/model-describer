{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#from sensitivity_plot import sensitivity_plot\n",
    "#import statsmodels.api as sm\n",
    "import numbers\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import linear_model\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import pylab \n",
    "import scipy.stats as stats\n",
    "from whitebox.eval import WhiteBoxSensitivity\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble.partial_dependence import partial_dependence, plot_partial_dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./datasets/final_data.csv', low_memory=False)\n",
    "#final_data = final_data.drop('LanguageRecommendationSelect', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5617, 282)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for details on data cleaning see'Data_Cleaning.ipynb'\n",
    "#raw data has 5617 rows\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5617, 282)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get rid of all NAs\n",
    "#final_data = final_data.dropna()\n",
    "df = df.reset_index(drop=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependentVar = 'JobSatisfaction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#these are too sparse so removing them actually makes the model slightly better\n",
    "spike_cols = [col for col in df.columns if 'WorkToolsSelect' in col]\n",
    "df = df.drop(spike_cols, axis=1)\n",
    "spike_cols = [col for col in df.columns if 'WorkHardwareSelect' in col]\n",
    "df = df.drop(spike_cols, axis=1)\n",
    "\n",
    "#drop country specific axis as it's hard to interpret and clouds the impact of other variables\n",
    "df= df.drop('Average Salary Within Country', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4364, 221)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop people who don't consider themselves Data Scientists\n",
    "\n",
    "df = df[df['DataScienceIdentitySelect'] !='No']\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4364.000000\n",
       "mean        6.880614\n",
       "std         2.108277\n",
       "min         1.000000\n",
       "25%         6.000000\n",
       "50%         7.000000\n",
       "75%         8.000000\n",
       "max        10.000000\n",
       "Name: JobSatisfaction, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[dependentVar].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1    4.0\n",
       "0.2    5.0\n",
       "0.3    6.0\n",
       "0.4    7.0\n",
       "0.5    7.0\n",
       "0.6    8.0\n",
       "0.7    8.0\n",
       "0.8    9.0\n",
       "0.9    9.0\n",
       "Name: JobSatisfaction, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop columns with WorkToolsSelect_C as they are sparse and not important here and have a ++ that is problematic\n",
    "df['JobSatisfaction'].quantile([.1,.2,.3,.4,.5,.6,.7,.8,.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#convert string variables to categorical variables \n",
    "#df[df.select_dtypes(['object']).columns] = df.select_dtypes(['object']).apply(lambda x: x.astype('category'))\n",
    "\n",
    "# select only those columns which are categorical in nature and make a copy for modeling\n",
    "#df.select_dtypes(include = ['object'])\n",
    "finaldf = df.copy(deep = True)\n",
    "\n",
    "# create dummies example using all categorical columns\n",
    "# this naming convention must be precise for WhiteBox to recognize what dummies are associated with what variables\n",
    "#dummies = pd.concat([pd.get_dummies(model_df.loc[:, col], prefix = col) for col in model_df.select_dtypes(include = ['object']).columns], axis = 1)\n",
    "\n",
    "finaldf = pd.concat([pd.get_dummies(finaldf.loc[:, finaldf.columns != dependentVar].select_dtypes(include=['category', 'O'])),\n",
    "           finaldf.select_dtypes(include=[np.number])], axis=1)\n",
    "\n",
    "# add the dummies to the numeric dataframe for modeling\n",
    "#model_df = pd.concat([model_df.select_dtypes(include = [np.number]), dummies], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make train and test samles\n",
    "X_train, X_test, y_train, y_test = train_test_split(finaldf.loc[:, finaldf.columns != dependentVar], df.loc[:, dependentVar], test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a Random Forest object trained to predict Job Satisfaction \n",
    "#Rf = RandomForestRegressor(n_estimators=50, min_weight_fraction_leaf = .01,  oob_score=True)\n",
    "#Rf.fit(xTrain,final_data['JobSatisfaction'])\n",
    "#Rf.fit(finaldf.loc[:, finaldf.columns != dependentVar],df.loc[:, dependentVar])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scores = cross_val_score(Rf, finaldf.loc[:, finaldf.columns != dependentVar], df.loc[:, dependentVar], cv=5)\n",
    "#print(scores)\n",
    "#print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.05, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.01,\n",
       "             n_estimators=200, presort='auto', random_state=25,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est = GradientBoostingRegressor(n_estimators=200, learning_rate=.05,  min_weight_fraction_leaf = .01, loss='ls', random_state = 25)\n",
    "est.fit(finaldf.loc[:, finaldf.columns != dependentVar], finaldf.loc[:, dependentVar])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4364, 1066)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.18925893 0.18992717 0.21035423 0.21166745 0.1718822 ]\n",
      "0.19461799567867424\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(est, finaldf.loc[:, finaldf.columns != dependentVar], finaldf.loc[:, dependentVar], cv=5)\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.03, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit lasso model\n",
    "lass = linear_model.Lasso(alpha=0.03)\n",
    "lass.fit(finaldf.loc[:, finaldf.columns != dependentVar],df.loc[:, dependentVar])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17855339 0.19955505 0.20235978 0.20088658 0.1630909 ]\n",
      "0.18888914219697164\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(lass, finaldf.loc[:, finaldf.columns != dependentVar], df.loc[:, dependentVar], cv=5)\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate coefficients and then print them\n",
    "coef_dict = {}\n",
    "for coef, feat in zip(lass.coef_,X_train.columns):\n",
    "    if coef != 0:\n",
    "        coef_dict[feat] = round(coef,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Varialbe</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>WorkChallengeFrequencyPolitics_Most of the time</td>\n",
       "      <td>-0.620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Continent_Asia</td>\n",
       "      <td>-0.458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TitleFit_Poorly</td>\n",
       "      <td>-0.396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>SalaryChange_Has stayed about the same (has no...</td>\n",
       "      <td>-0.286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RemoteWork_Never</td>\n",
       "      <td>-0.216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>WorkChallengeFrequencyTalent_Most of the time</td>\n",
       "      <td>-0.174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>CurrentEmployerType_Employed by a company that...</td>\n",
       "      <td>-0.142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>WorkChallengeFrequencyDataAccess_Never</td>\n",
       "      <td>-0.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>WorkChallengeFrequencyDirtyData_Never</td>\n",
       "      <td>-0.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>JobFunctionSelect_Analyze and understand data ...</td>\n",
       "      <td>-0.066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DataScienceIdentitySelect_Sort of (Explain more)</td>\n",
       "      <td>-0.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>WorkMethodsFrequencyTextAnalysis_Never</td>\n",
       "      <td>-0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>NumberChallenges</td>\n",
       "      <td>-0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>WorkChallengeFrequencyPrivacy_Never</td>\n",
       "      <td>-0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>WorkDataVisualizations_10-25% of projects</td>\n",
       "      <td>-0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>WorkDataVisualizations_Less than 10% of projects</td>\n",
       "      <td>-0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>LearningCategoryKaggle</td>\n",
       "      <td>-0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>LearningCategoryOnlineCourses</td>\n",
       "      <td>-0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WorkToolsFrequencyJupyter_Never</td>\n",
       "      <td>-0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>LearningCategorySelftTaught</td>\n",
       "      <td>-0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>LearningCategoryUniversity</td>\n",
       "      <td>-0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Unnamed: 0</td>\n",
       "      <td>-0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>CurrentEmployerType_Employed by a company that...</td>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>TimeVisualizing</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>LearningCategoryWork</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CurrentJobTitleSelect_Data Scientist</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>TimeGatheringData</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>TimeOtherSelect</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>TimeFindingInsights</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>TimeProduction</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>TimeModelBuilding</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>NumberPlatforms</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Continent_Other</td>\n",
       "      <td>0.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>CurrentEmployerType_Employed by a company that...</td>\n",
       "      <td>0.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WorkToolsFrequencyJupyter_Most of the time</td>\n",
       "      <td>0.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EmployerSizeChange_Increased slightly</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Hardware Types Used</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Number of Algorithims</td>\n",
       "      <td>0.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Percent Above/Below Average Salary</td>\n",
       "      <td>0.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>UniversityImportance_Very important</td>\n",
       "      <td>0.069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>WorkMethodsFrequencyDataVisualization_Most of ...</td>\n",
       "      <td>0.073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>WorkChallengeFrequencyUnusedResults_Never</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>WorkChallengeFrequencyTalent_Never</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EmployerSizeChange_Increased significantly</td>\n",
       "      <td>0.190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SalaryChange_Has increased 20% or more</td>\n",
       "      <td>0.299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TitleFit_Perfectly</td>\n",
       "      <td>0.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>WorkChallengeFrequencyPolitics_Never</td>\n",
       "      <td>0.587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Varialbe  Coefficient\n",
       "12    WorkChallengeFrequencyPolitics_Most of the time       -0.620\n",
       "25                                     Continent_Asia       -0.458\n",
       "2                                     TitleFit_Poorly       -0.396\n",
       "24  SalaryChange_Has stayed about the same (has no...       -0.286\n",
       "22                                   RemoteWork_Never       -0.216\n",
       "16      WorkChallengeFrequencyTalent_Most of the time       -0.174\n",
       "29  CurrentEmployerType_Employed by a company that...       -0.142\n",
       "19             WorkChallengeFrequencyDataAccess_Never       -0.079\n",
       "15              WorkChallengeFrequencyDirtyData_Never       -0.072\n",
       "7   JobFunctionSelect_Analyze and understand data ...       -0.066\n",
       "3    DataScienceIdentitySelect_Sort of (Explain more)       -0.062\n",
       "11             WorkMethodsFrequencyTextAnalysis_Never       -0.043\n",
       "44                                   NumberChallenges       -0.040\n",
       "18                WorkChallengeFrequencyPrivacy_Never       -0.037\n",
       "20          WorkDataVisualizations_10-25% of projects       -0.020\n",
       "21   WorkDataVisualizations_Less than 10% of projects       -0.018\n",
       "35                             LearningCategoryKaggle       -0.010\n",
       "32                      LearningCategoryOnlineCourses       -0.010\n",
       "9                     WorkToolsFrequencyJupyter_Never       -0.010\n",
       "31                        LearningCategorySelftTaught       -0.007\n",
       "34                         LearningCategoryUniversity       -0.004\n",
       "42                                         Unnamed: 0       -0.001\n",
       "28  CurrentEmployerType_Employed by a company that...       -0.000\n",
       "39                                    TimeVisualizing        0.001\n",
       "33                               LearningCategoryWork        0.002\n",
       "0                CurrentJobTitleSelect_Data Scientist        0.003\n",
       "36                                  TimeGatheringData        0.003\n",
       "41                                    TimeOtherSelect        0.003\n",
       "40                                TimeFindingInsights        0.007\n",
       "38                                     TimeProduction        0.008\n",
       "37                                  TimeModelBuilding        0.009\n",
       "30                                                Age        0.016\n",
       "45                                    NumberPlatforms        0.018\n",
       "26                                    Continent_Other        0.024\n",
       "27  CurrentEmployerType_Employed by a company that...        0.024\n",
       "8          WorkToolsFrequencyJupyter_Most of the time        0.024\n",
       "5               EmployerSizeChange_Increased slightly        0.025\n",
       "46                                Hardware Types Used        0.030\n",
       "47                              Number of Algorithims        0.047\n",
       "43                 Percent Above/Below Average Salary        0.051\n",
       "6                 UniversityImportance_Very important        0.069\n",
       "10  WorkMethodsFrequencyDataVisualization_Most of ...        0.073\n",
       "14          WorkChallengeFrequencyUnusedResults_Never        0.080\n",
       "17                 WorkChallengeFrequencyTalent_Never        0.080\n",
       "4          EmployerSizeChange_Increased significantly        0.190\n",
       "23             SalaryChange_Has increased 20% or more        0.299\n",
       "1                                  TitleFit_Perfectly        0.325\n",
       "13               WorkChallengeFrequencyPolitics_Never        0.587"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(coef_dict.items()), columns=['Varialbe', 'Coefficient']).sort_values(['Coefficient'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test validity of assumptions of the regression's coefficients \n",
    "y = y_test\n",
    "predicted = lass.predict(X_test)\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(y, predicted, edgecolors=(0, 0, 0))\n",
    "#ax.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=6)\n",
    "ax.set_xlabel('Measured')\n",
    "ax.set_ylabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y_test\n",
    "predicted = lass.predict(X_test)\n",
    "error2 = (predicted-y_test)\n",
    "stats.probplot(error2, dist=\"norm\", plot=pylab)\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CurrentJobTitleSelect_Data Scientist\n",
      "TitleFit_Perfectly\n",
      "TitleFit_Poorly\n",
      "DataScienceIdentitySelect_Sort of (Explain more)\n",
      "EmployerSizeChange_Increased significantly\n",
      "EmployerSizeChange_Increased slightly\n",
      "UniversityImportance_Very important\n",
      "JobFunctionSelect_Analyze and understand data to influence product or business decisions\n",
      "WorkToolsFrequencyJupyter_Most of the time\n",
      "WorkToolsFrequencyJupyter_Never\n",
      "WorkMethodsFrequencyDataVisualization_Most of the time\n",
      "WorkMethodsFrequencyTextAnalysis_Never\n",
      "WorkChallengeFrequencyPolitics_Most of the time\n",
      "WorkChallengeFrequencyPolitics_Never\n",
      "WorkChallengeFrequencyUnusedResults_Never\n",
      "WorkChallengeFrequencyDirtyData_Never\n",
      "WorkChallengeFrequencyTalent_Most of the time\n",
      "WorkChallengeFrequencyTalent_Never\n",
      "WorkChallengeFrequencyPrivacy_Never\n",
      "WorkChallengeFrequencyDataAccess_Never\n",
      "WorkDataVisualizations_10-25% of projects\n",
      "WorkDataVisualizations_Less than 10% of projects\n",
      "RemoteWork_Never\n",
      "SalaryChange_Has increased 20% or more\n",
      "SalaryChange_Has stayed about the same (has not increased or decreased more than 5%)\n",
      "Continent_Asia\n",
      "Continent_Other\n",
      "CurrentEmployerType_Employed by a company that doesn't perform advanced analytics_No\n",
      "CurrentEmployerType_Employed by a company that doesn't perform advanced analytics_Yes\n",
      "CurrentEmployerType_Employed by a company that performs advanced analytics_No\n",
      "Age\n",
      "LearningCategorySelftTaught\n",
      "LearningCategoryOnlineCourses\n",
      "LearningCategoryWork\n",
      "LearningCategoryUniversity\n",
      "LearningCategoryKaggle\n",
      "TimeGatheringData\n",
      "TimeModelBuilding\n",
      "TimeProduction\n",
      "TimeVisualizing\n",
      "TimeFindingInsights\n",
      "TimeOtherSelect\n",
      "Unnamed: 0\n",
      "Percent Above/Below Average Salary\n",
      "NumberChallenges\n",
      "NumberPlatforms\n",
      "Hardware Types Used\n",
      "Number of Algorithims\n"
     ]
    }
   ],
   "source": [
    "j=221\n",
    "\n",
    "\n",
    "for i in range(0,len(coef_dict)):\n",
    "    fig, ax = plt.subplots()\n",
    "    temp = X_test[list(coef_dict)[i]]\n",
    "    x = temp.sort_values()\n",
    "    #print(len(temp.sort_values))\n",
    "    y=error2\n",
    "    fit = np.polyfit(x, y, deg=1)\n",
    "    ax.plot(x, fit[0] * x + fit[1], color='red')\n",
    "    ax.scatter(x, y)\n",
    "    print(list(coef_dict)[i])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = est.feature_importances_\n",
    "feature_length = feature_importance.shape[0]\n",
    "feature_10 = feature_length-20\n",
    "# make importances relative to max importance\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot top 10 features based on importance\n",
    "feature_importance = est.feature_importances_\n",
    "feature_length = feature_importance.shape[0]\n",
    "feature_10 = feature_length-20\n",
    "# make importances relative to max importance\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "#sorted_idx=sorted_idx[0:10]\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.barh(pos[feature_10:feature_length], feature_importance[sorted_idx][feature_10:feature_length], align='center')\n",
    "plt.yticks(pos[feature_10:feature_length], np.array(list(X_train))[sorted_idx][feature_10:feature_length])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WorkChallengeFrequencyPolitics</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Most of the time</th>\n",
       "      <td>462.0</td>\n",
       "      <td>5.402597</td>\n",
       "      <td>2.447327</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Never</th>\n",
       "      <td>2628.0</td>\n",
       "      <td>7.298706</td>\n",
       "      <td>1.938384</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Often</th>\n",
       "      <td>691.0</td>\n",
       "      <td>6.415340</td>\n",
       "      <td>2.040814</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rarely</th>\n",
       "      <td>59.0</td>\n",
       "      <td>6.830508</td>\n",
       "      <td>2.190517</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sometimes</th>\n",
       "      <td>524.0</td>\n",
       "      <td>6.706107</td>\n",
       "      <td>1.943140</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 count      mean       std  min  25%  50%  \\\n",
       "WorkChallengeFrequencyPolitics                                              \n",
       "Most of the time                 462.0  5.402597  2.447327  1.0  4.0  6.0   \n",
       "Never                           2628.0  7.298706  1.938384  1.0  6.0  8.0   \n",
       "Often                            691.0  6.415340  2.040814  1.0  5.0  7.0   \n",
       "Rarely                            59.0  6.830508  2.190517  1.0  5.0  7.0   \n",
       "Sometimes                        524.0  6.706107  1.943140  1.0  6.0  7.0   \n",
       "\n",
       "                                75%   max  \n",
       "WorkChallengeFrequencyPolitics             \n",
       "Most of the time                7.0  10.0  \n",
       "Never                           9.0  10.0  \n",
       "Often                           8.0  10.0  \n",
       "Rarely                          8.0  10.0  \n",
       "Sometimes                       8.0  10.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['WorkChallengeFrequencyPolitics'])['JobSatisfaction'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WorkChallengeFrequencyPolitics\n",
       "Most of the time    0.105866\n",
       "Never               0.602200\n",
       "Often               0.158341\n",
       "Rarely              0.013520\n",
       "Sometimes           0.120073\n",
       "Name: WorkChallengeFrequencyPolitics, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['WorkChallengeFrequencyPolitics'])['WorkChallengeFrequencyPolitics'].count()/df['WorkChallengeFrequencyPolitics'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Entire_Population'] = 'Entire Population'\n",
    "df['Entire_Population'] = df['Entire_Population'].astype('object')\n",
    "\n",
    "#df['Entire_Population'] = pd.Categorical(df['Entire_Population'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Entire_Population']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spike_cols = [col for col in df.columns if 'Population' in col]\n",
    "spike_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'Average Salary Within Country' : 'Average Salary Within Country',  \n",
    "featuredict = { 'WorkChallengeFrequencyPolitics' : 'Frequency of Political Work Issues', \n",
    "               'WorkDataVisualizations' : 'Percent of Work Making Visuals',\n",
    "               'MLToolNextYearSelect' : 'Machine Learning Tool I Plan to Learn Next',\n",
    "                             'TimeModelBuilding' : 'Time Spent Model Building',\n",
    "                             'Number of Algorithims' : 'Number of Algorithms',\n",
    "                             'SalaryChange' : 'Salary Change',\n",
    "                             'EmployerSizeChange' : 'YoY Change in Employer Size',\n",
    "                             'Percent Above/Below Average Salary' : 'Percent Above/Below Average Salary',              \n",
    "                             'LearningCategoryWork' : 'Proportion of Knowledge Gained From Work',\n",
    "                             'LearningCategoryOnlineCourses': 'Proportion of Knowledge Gained Online',\n",
    "                             'LearningPlatformUsefulnessCompany' : 'Usefulness of Firm Learning Platform',\n",
    "                             'WorkChallengeFrequencyDomainExpertise' : 'Frequency of Personally Lacking Domain Expertise',\n",
    "                             'WorkChallengeFrequencyTalent' : 'Challenge in finding talent',\n",
    "               'WorkChallengeFrequencyML' : 'Work Challenge - Machine Learning',\n",
    "                             'RemoteWork' : 'Remote Work',\n",
    "                             'Age' : 'Age',\n",
    "                             'TitleFit' : 'Title Fit',\n",
    "                                     'DataScienceIdentitySelect' : 'Data Scientist Identity',\n",
    "             \n",
    "                             'Continent' : 'Continent',\n",
    "                             'SalaryChange' : 'YoY Salary Change',\n",
    "                             'JobSatisfaction' : 'Job Satisfaction',\n",
    "                             'AlgorithmUnderstandingLevel' : 'Algorithm Understanding Level',\n",
    "                              'UniversityImportance' : 'Importance of Attending a University',\n",
    "               'Entire_Population' : 'Entire Population'\n",
    "                         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple featuredict as a trial\n",
    "featuredict ={'TimeModelBuilding' : 'Time Spent Model Building',\n",
    "             'Continent' : 'Continent'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "WB=None\n",
    "\n",
    "WB = WhiteBoxSensitivity(est,\n",
    "                    model_df=finaldf,\n",
    "                    ydepend=dependentVar,\n",
    "                    cat_df=df,\n",
    "                    groupbyvars=['Continent'],\n",
    "                    aggregate_func=np.mean,\n",
    "                          featuredict  = featuredict,\n",
    "                    verbose=None,\n",
    "                     std_num=1, \n",
    "                          \n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4364, 1065)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unwanted_pred_cols = [dependentVar, 'predictedYSmooth']\n",
    "finaldf.loc[:, list(set(finaldf.columns).difference(set(unwanted_pred_cols)))].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.32692549, 6.4336189 , 6.01148632, ..., 6.18638987, 5.48770752,\n",
       "       6.26802623])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.predict(finaldf.loc[:, list(set(finaldf.columns).difference(set(unwanted_pred_cols)))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features is 1065 and input n_features is 1066 ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Tester\\WhiteBox_Production\\whitebox\\base.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, output_type, output_path)\u001b[0m\n\u001b[0;32m    213\u001b[0m                                                        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cat_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m                                                        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mydepend\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m                                                        self.model_type)\n\u001b[0m\u001b[0;32m    216\u001b[0m         \u001b[1;31m# create placeholder for outputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m         \u001b[0mplaceholder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Tester\\WhiteBox_Production\\whitebox\\utils\\fmt_model_outputs.py\u001b[0m in \u001b[0;36mfmt_sklearn_preds\u001b[1;34m(predict_engine, modelobj, model_df, cat_df, ydepend, model_type)\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;31m# create predictions, filter out extraneous columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     preds = predict_engine(\n\u001b[1;32m---> 34\u001b[1;33m         model_df.loc[:, list(set(model_df.columns).difference(set(unwanted_pred_cols)))])\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'regression'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\whiteboxenv\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1890\u001b[0m         \"\"\"\n\u001b[0;32m   1891\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"C\"\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1892\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1894\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstaged_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\whiteboxenv\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36m_decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         \u001b[1;31m# for use in inner loop, not raveling the output in single-class case,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1129\u001b[0m         \u001b[1;31m# not doing input validation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1130\u001b[1;33m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[0mpredict_stages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\whiteboxenv\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36m_init_decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1118\u001b[0m         \u001b[1;34m\"\"\"Check input and compute prediction of ``init``. \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1120\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m             raise ValueError(\"X.shape[1] should be {0:d}, not {1:d}.\".format(\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\whiteboxenv\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    382\u001b[0m                              \u001b[1;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m                              \u001b[1;34m\"input n_features is %s \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m                              % (self.n_features_, n_features))\n\u001b[0m\u001b[0;32m    385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 1065 and input n_features is 1066 "
     ]
    }
   ],
   "source": [
    "%%time \n",
    "WB.run(output_type='html',\n",
    "       output_path='ds_output_new.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dbyler\\Desktop\\Tester\\WhiteBox_Production\\docs\\notebooks\n",
      "C:\\Users\\dbyler\\Desktop\\Tester\\WhiteBox_Production\\docs\\notebooks\n"
     ]
    }
   ],
   "source": [
    "WB.save('./DS_Satisfaction_featuredict_dsonly_withmltoolselect.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dbyler\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:523: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n",
      "C:\\Users\\dbyler\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py:3239: UserWarning: Attempting to set identical bottom==top results\n",
      "in singular transformations; automatically expanding.\n",
      "bottom=4.896257010944538e-16, top=4.896257010944538e-16\n",
      "  'bottom=%s, top=%s') % (bottom, top))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#\n",
    "for i in range(0,finaldf.loc[:, finaldf.columns != dependentVar].shape[1]):\n",
    "                  my_plots = plot_partial_dependence(est, features=[i], # column numbers of plots we want to show \n",
    "                        X=finaldf.loc[:, finaldf.columns != dependentVar],            # raw predictors data.\n",
    "                              #feature_names=[finaldf.columns[finaldf.columns != dependentVar][i]],\n",
    "                                   grid_resolution=100) # number of values to plot on x axis\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4364, 1066)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Item wrong length 1066 instead of 4364.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-106-3667fa56050c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'all'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfinaldf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfinaldf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mdependentVar\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1956\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1957\u001b[0m             \u001b[1;31m# either boolean or fancy integer index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1958\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1959\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1960\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1993\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1994\u001b[0m                 raise ValueError('Item wrong length %d instead of %d.' %\n\u001b[1;32m-> 1995\u001b[1;33m                                  (len(key), len(self.index)))\n\u001b[0m\u001b[0;32m   1996\u001b[0m             \u001b[1;31m# check_bool_indexer will throw exception if Series key cannot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1997\u001b[0m             \u001b[1;31m# be reindexed to match DataFrame rows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Item wrong length 1066 instead of 4364."
     ]
    }
   ],
   "source": [
    "plt.close('all')\n",
    "finaldf[finaldf.columns != dependentVar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#seeing if we get a differnet result for a classifier\n",
    "\n",
    "y_train_binary = np.where(y_train < y_train.mean() , 1, 0)\n",
    "y_test_binary = np.where(y_test < y_train.mean() , 1, 0)\n",
    "\n",
    "modelObject = GradientBoostingClassifier(n_estimators=500,   max_features = 'sqrt', learning_rate=.01)\n",
    "modelObject.fit(X_train,y_train_binary)\n",
    "y_in_pred = modelObject.predict(X_train)\n",
    "y_out_pred=modelObject.predict(X_test)\n",
    "print(accuracy_score(y_train_binary, y_in_pred)) \n",
    "print(accuracy_score(y_test_binary, y_out_pred))  \n",
    "\n",
    "# Plot top 10 feature importance\n",
    "feature_importance = modelObject.feature_importances_\n",
    "feature_length = feature_importance.shape[0]\n",
    "feature_10 = feature_length-15\n",
    "# make importances relative to max importance\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "#sorted_idx=sorted_idx[0:10]\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.barh(pos[feature_10:feature_length], feature_importance[sorted_idx][feature_10:feature_length], align='center')\n",
    "plt.yticks(pos[feature_10:feature_length], np.array(list(X_train))[sorted_idx][feature_10:feature_length])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#feature dictionary for when the dependent variable is binary\n",
    "\n",
    "FeatureDict = {'WorkChallengeFrequencyPolitics' : 'Frequency of Political Work Issues', \n",
    "               'WorkChallengeUnusedResults' : 'Frequency of Results Not Being Used', \n",
    "               'Number of Algorithims' : 'Number of Algorithims',\n",
    "               'TitleFit' : 'Goodness of Title Fit',\n",
    "               'Number of Code Sharing Methods': 'Number of Code Sharing Methods',\n",
    "               'LearningCategoryOnlineCourses' : 'Share of Learning Done Online', \n",
    "               'Continent' : 'Continent',\n",
    "               'SalaryChange' : 'Salary Change',\n",
    "               'LearningCategoryWork' : 'Proportion of Knowledge Gained From Work',\n",
    "               'EmployerSizeChange' : 'Change in Employer Size',\n",
    "               'WorkChallengeFrequencyTalent' : 'Difficulty Sourcing Talented Colleagues',\n",
    "               'WorkProductionFrequency' : 'Frequency of Production-style Work',\n",
    "               'TimeModelBuilding' : 'Proportion of Time Spent Model Building',\n",
    "               'CompnesationUSD' : 'Compensation ($)',\n",
    "               'RemoteWork' : 'Frequency of Remote Work',\n",
    "               'DataScienceIdentitySelect' : 'Views self as Data Scientist',\n",
    "               'WorkChallengeFrequencyML' : 'Frequency of working with machine learning',\n",
    "               'UniversityImportance' : 'Importance of a University degree'\n",
    "              }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calls to our new functions for the classifiers go here\n",
    "\n",
    "#Error plot\n",
    "\n",
    "#Sensitivty plot\n",
    "print(sensitivity_plot(X_test.join(y_test),'JobSatisfaction',cont_independentVar,cat_independentVar,\n",
    "                               Rf,ouputPath,'Data Scienctist Job Satisfaction',['Continent', 'WorkChallengeFrequencyPolitics']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
